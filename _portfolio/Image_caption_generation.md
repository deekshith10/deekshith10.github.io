---
title: "Advanced Image Caption Generation using Attention Mechanism"
excerpt: "Developed an image captioning system that leverages the combination of computer vision and language
processing along with improvements in the encoder-decoder structure involving the CNNs and LSTM
networks.<br/><img src='/images/image_caption.png'>"
collection: portfolio
---
<img src='/images/image_caption.png'> <br/>
<img src='/images/image_caption2.png'><br/>

This project intricately involves an interaction between computer vision and natural language processing, leveraging advanced neural network architectures.

**Project Overview:**
- The challenge focuses on refining the encoder-decoder architecture, where Convolutional Neural Networks (CNNs) play a pivotal role in extracting salient features from images. These features are then passed to Recurrent Neural Networks (RNNs), especially Long Short-Term Memory (LSTM) networks, orchestrating the generation of captions.
-The integration of attention mechanisms is a groundbreaking contribution, enabling dynamic focus on different areas of an image during caption generation, thereby improving the quality and relevance of descriptions. **Web 
-After training the model, we generate captions from test data and visualize the imageâ€™s attention. 

Attention mechanism allows for greater accuracy and significance of captions as shown by the high BLEU score (50-55) that was constantly recorded during the process of evaluation.